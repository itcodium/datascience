{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import urllib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "pickle.dump(mnist, open( \"mnist.pickle\", \"wb\" ))\n",
    "\n",
    "target_page ='http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.bz2'\n",
    "with urllib.request.urlopen(target_page) as response:\n",
    "    with open('ijcnn1.bz2','wb') as W:\n",
    "        W.write(response.read())\n",
    "\n",
    "target_page ='http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/cadata'\n",
    "cadata = load_svmlight_file(urllib.request.urlopen(target_page))\n",
    "pickle.dump(cadata, open( \"cadata.pickle\", \"wb\" ))\n",
    "\n",
    "covertype_dataset = fetch_covtype(random_state=101, shuffle=True)\n",
    "pickle.dump(covertype_dataset, open( \"covertype_dataset.pickle\", \"wb\" ))\n",
    "\n",
    "newsgroups_dataset = fetch_20newsgroups(shuffle=True, remove=('headers','footers', 'quotes'), random_state=6)\n",
    "pickle.dump(newsgroups_dataset, open( \"newsgroups_dataset.pickle\", \"wb\" ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load boston dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in the example, 80 percent of our dataset goes in training and 20 percent in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(boston.data,boston.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We're going to train and fit the regressor in the training set and predict the target variable in the test dataset. We are then going to measure the accuracy of the regression task by using the MAE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 3.842810589450487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, Y_train)\n",
    "Y_pred = regr.predict(X_test)\n",
    "\n",
    "print (\"MAE\", mean_absolute_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714 µs ± 60.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "%timeit regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "avg_price_house = np.average(boston.target)\n",
    "high_priced_idx = (Y_train >= avg_price_house)\n",
    "\n",
    "Y_train[high_priced_idx] = 1\n",
    "Y_train[np.logical_not(high_priced_idx)] = 0\n",
    "Y_train = Y_train.astype(np.int8)\n",
    "\n",
    "high_priced_idx = (Y_test >= avg_price_house)\n",
    "Y_test[high_priced_idx] = 1\n",
    "Y_test[np.logical_not(high_priced_idx)] = 0\n",
    "Y_test = Y_test.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.92      0.86        61\n",
      "          1       0.85      0.68      0.76        41\n",
      "\n",
      "avg / total       0.83      0.82      0.82       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print (classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The precision and recall values are over 80 percent. This is already a good result for a very simple method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.73 ms ± 167 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
